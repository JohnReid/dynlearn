
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>dynlearn: dynamical system active learning &#8212; dynlearn 0.1 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="dynlearn-dynamical-system-active-learning">
<h1>dynlearn: dynamical system active learning<a class="headerlink" href="#dynlearn-dynamical-system-active-learning" title="Permalink to this headline">¶</a></h1>
<p>A dynamical system can be driven in different directions depending on
a forcing external input to the system. The aim is to find optimal inputs
so that the system produces certain species to a specified target level.
In an iterative active learning cycle the inputs are successively
optimised towards that target with experiments performed using the
suggested inputs. Since the dynamics of the system is
unknown it is approximated by a Gaussian process regression.</p>
<div class="toctree-wrapper compound">
</div>
</div>
<div class="section" id="module-dynlearn.demo">
<span id="demo-optimise-gene-expression"></span><h1>Demo: optimise gene expression<a class="headerlink" href="#module-dynlearn.demo" title="Permalink to this headline">¶</a></h1>
<p>The module provides functionality to optimise the input to an unknown dynamical
system (but with known or estimated dimension) to achieve a certain production
level for a target species at a specified time point.</p>
<dl class="function">
<dt id="dynlearn.demo.nanog_demo">
<code class="descclassname">dynlearn.demo.</code><code class="descname">nanog_demo</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/dynlearn/demo.html#nanog_demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.demo.nanog_demo" title="Permalink to this definition">¶</a></dt>
<dd><p>Optimise input so that a target level of NANOG is produced in the Biomodel
<a class="reference external" href="https://www.ebi.ac.uk/biomodels/BIOMD0000000203">Chickarmane2006 - Stem cell switch reversible</a>
The model is simulated using a ODE solver of the
<a class="reference external" href="http://tellurium.analogmachine.org/">Tellurium</a>
package for biomolecular models.</p>
<p>To optimise the output a Gaussian process state space model (GPSSM) is
constructed from an initial and <code class="docutils literal notranslate"><span class="pre">n_epochs</span></code> follow-up experiments. All
species levels of the system at a particular simulation step are input to
the GP, and the increase or decrease in the next simulation step is the
output, ie, there is one GP for each species (assumed to be independent
conditional on the common input). The settings for the Gaussian process
gp parameters (lengthscales for the inputs, variance, and error
variance for the output squared exponential gp) are chosen manually
to fit the range of the variables.</p>
<p>The aim is to achieve a level of 50 for NANOG by simulation step 20 (real
time 10). Input is only allowed at steps 0, 5, and 10. The input is
limited to [0.0,1000.0].</p>
<p>The optimisation takes a few minutes on a typical workstation. However,
depending on random settings it might take more or fewer epochs to find
an input that induces the desired level of NANOG.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Successive optimisation results are stored in a results file
than can be loaded and displayed by running <code class="docutils literal notranslate"><span class="pre">dynlearn/demo_plots.py</span></code></td>
</tr>
</tbody>
</table>
<p>Call for example under Unix by:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python3</span> <span class="n">dynlearn</span><span class="o">/</span><span class="n">demo</span><span class="o">.</span><span class="n">py</span>
<span class="n">python3</span> <span class="n">dynlearn</span><span class="o">/</span><span class="n">demo_plots</span><span class="o">.</span><span class="n">py</span>
<span class="n">display</span> <span class="n">dynlearn</span><span class="o">/</span><span class="n">results</span><span class="o">/</span><span class="n">Nanog_target_50</span><span class="o">.</span><span class="n">png</span>
</pre></div>
</div>
</dd></dl>

<a class="reference internal image-reference" href="_images/Nanog_target_50.png"><img alt="_images/Nanog_target_50.png" src="_images/Nanog_target_50.png" style="width: 600px;" /></a>
</div>
<div class="section" id="module-dynlearn.simulation">
<span id="simulation"></span><h1>Simulation<a class="headerlink" href="#module-dynlearn.simulation" title="Permalink to this headline">¶</a></h1>
<p>Simulation of discrete and continuous dynamical systems</p>
<p><a class="reference internal" href="#dynlearn.simulation.DiscreteSimulation" title="dynlearn.simulation.DiscreteSimulation"><code class="xref py py-class docutils literal notranslate"><span class="pre">DiscreteSimulation</span></code></a> implements a discrete step solver,
while <a class="reference internal" href="#dynlearn.simulation.ContinuousSimulation" title="dynlearn.simulation.ContinuousSimulation"><code class="xref py py-class docutils literal notranslate"><span class="pre">ContinuousSimulation</span></code></a> applies the
<a class="reference external" href="http://tellurium.analogmachine.org/">Tellurium</a> package to solve
ODE models written in the <a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2735663/">Antimony</a>
systems biology model language.</p>
<p class="rubric">Example</p>
<p>Use the subclass <a class="reference internal" href="#dynlearn.simulation.StemCellSwitch" title="dynlearn.simulation.StemCellSwitch"><code class="xref py py-class docutils literal notranslate"><span class="pre">StemCellSwitch</span></code></a> of <a class="reference internal" href="#dynlearn.simulation.ContinuousSimulation" title="dynlearn.simulation.ContinuousSimulation"><code class="xref py py-class docutils literal notranslate"><span class="pre">ContinuousSimulation</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sim</span> <span class="o">=</span> <span class="n">StemCellSwitch</span><span class="p">(</span><span class="n">n_times</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">real_time</span><span class="o">=</span><span class="mf">10.0</span><span class="p">)</span>
<span class="n">input_tracks</span> <span class="o">=</span> <span class="n">sim3</span><span class="o">.</span><span class="n">u_tracks_from_knots</span><span class="p">(</span><span class="n">sim3</span><span class="o">.</span><span class="n">n_times</span><span class="p">,</span> <span class="n">knots</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span>
                                        <span class="n">knot_values</span><span class="o">=</span><span class="p">[</span><span class="mf">500.0</span><span class="p">,</span><span class="mf">300.0</span><span class="p">,</span><span class="mf">100.0</span><span class="p">])</span>
<span class="n">sim</span><span class="o">.</span><span class="n">set_inputs</span><span class="p">(</span><span class="n">tracks</span><span class="o">=</span><span class="n">input_tracks</span><span class="p">,</span>
                <span class="n">time_inds</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">input_tracks</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

<span class="n">sim</span><span class="o">.</span><span class="n">dynamic_simulate</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
<p>This class uses a ‘step’ version of the input, ie, input is held constant
at the last knot value, eg, at step 7 the value is 300.0.</p>
<dl class="class">
<dt id="dynlearn.simulation.ContinuousSimulation">
<em class="property">class </em><code class="descclassname">dynlearn.simulation.</code><code class="descname">ContinuousSimulation</code><span class="sig-paren">(</span><em>n_times</em>, <em>u_tracks_from_knots</em>, <em>real_time</em>, <em>output_vars</em>, <em>u_type</em>, <em>model_str=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dynlearn/simulation.html#ContinuousSimulation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.simulation.ContinuousSimulation" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses the <a class="reference external" href="http://tellurium.analogmachine.org/">Tellurium</a> Antinomy
model loader and the <a class="reference external" href="https://libroadrunner.readthedocs.io/en/latest/">roadRunner</a> ODE solver to
simulate dynamical models.</p>
</dd></dl>

<dl class="class">
<dt id="dynlearn.simulation.DiscreteSimulation">
<em class="property">class </em><code class="descclassname">dynlearn.simulation.</code><code class="descname">DiscreteSimulation</code><span class="sig-paren">(</span><em>n_times</em>, <em>u_tracks_from_knots</em>, <em>output_vars</em>, <em>x_start</em>, <em>u_type</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dynlearn/simulation.html#DiscreteSimulation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.simulation.DiscreteSimulation" title="Permalink to this definition">¶</a></dt>
<dd><p>Solves a dynamical system by iteratively applying a transition function <code class="docutils literal notranslate"><span class="pre">f_trans</span></code>
to the current state values.</p>
<dl class="method">
<dt id="dynlearn.simulation.DiscreteSimulation.dynamic_simulate">
<code class="descname">dynamic_simulate</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/dynlearn/simulation.html#DiscreteSimulation.dynamic_simulate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.simulation.DiscreteSimulation.dynamic_simulate" title="Permalink to this definition">¶</a></dt>
<dd><p>Generic discrete solver, applies <code class="docutils literal notranslate"><span class="pre">self.f_trans</span></code> iteratively to
current state and input</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="dynlearn.simulation.FeedForwardOrCSimulation">
<em class="property">class </em><code class="descclassname">dynlearn.simulation.</code><code class="descname">FeedForwardOrCSimulation</code><span class="sig-paren">(</span><em>n_times</em>, <em>real_time=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dynlearn/simulation.html#FeedForwardOrCSimulation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.simulation.FeedForwardOrCSimulation" title="Permalink to this definition">¶</a></dt>
<dd><p>A simple example of a regulatory feedforward loop implemented as Antinomy
model: U0 activates both, X1 and X2, but X2 is inhibited by X1. For
details see the OR-gate I1 FFL in <a class="reference external" href="https://www.ncbi.nlm.nih.gov/pubmed/26072513">Ocone et al,
2015</a></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>n_times</strong> – number of simulation steps</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="dynlearn.simulation.FeedForwardOrDSimulation">
<em class="property">class </em><code class="descclassname">dynlearn.simulation.</code><code class="descname">FeedForwardOrDSimulation</code><span class="sig-paren">(</span><em>n_times</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dynlearn/simulation.html#FeedForwardOrDSimulation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.simulation.FeedForwardOrDSimulation" title="Permalink to this definition">¶</a></dt>
<dd><p>A discrete version of a feedforward network, details see
<a class="reference internal" href="#dynlearn.simulation.FeedForwardOrCSimulation" title="dynlearn.simulation.FeedForwardOrCSimulation"><code class="xref py py-class docutils literal notranslate"><span class="pre">FeedForwardOrCSimulation</span></code></a></p>
</dd></dl>

<dl class="class">
<dt id="dynlearn.simulation.Simulation">
<em class="property">class </em><code class="descclassname">dynlearn.simulation.</code><code class="descname">Simulation</code><a class="reference internal" href="_modules/dynlearn/simulation.html#Simulation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.simulation.Simulation" title="Permalink to this definition">¶</a></dt>
<dd><p>Generic simulation class</p>
</dd></dl>

<dl class="class">
<dt id="dynlearn.simulation.StemCellSwitch">
<em class="property">class </em><code class="descclassname">dynlearn.simulation.</code><code class="descname">StemCellSwitch</code><span class="sig-paren">(</span><em>n_times</em>, <em>real_time</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dynlearn/simulation.html#StemCellSwitch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.simulation.StemCellSwitch" title="Permalink to this definition">¶</a></dt>
<dd><p>Simulation of Biomodel
<a class="reference external" href="https://www.ebi.ac.uk/biomodels/BIOMD0000000203">Chickarmane2006 - Stem cell switch reversible</a>
The model is simulated using a ODE solver of the
<a class="reference external" href="http://tellurium.analogmachine.org/">Tellurium</a>
package for biomolecular models.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>n_times</strong> – number of simulation steps</li>
<li><strong>real_time</strong> – corresponding simulation time for ODE solver</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="dynlearn.simulation.demo">
<code class="descclassname">dynlearn.simulation.</code><code class="descname">demo</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/dynlearn/simulation.html#demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.simulation.demo" title="Permalink to this definition">¶</a></dt>
<dd><p>Demonstrates usage of simulation classes</p>
</dd></dl>

</div>
<div class="section" id="module-dynlearn.gp_kernels">
<span id="gaussian-process"></span><h1>Gaussian process<a class="headerlink" href="#module-dynlearn.gp_kernels" title="Permalink to this headline">¶</a></h1>
<p>Basic Gaussian process functionality for squared exponential kernel</p>
<p>The <a class="reference internal" href="#dynlearn.gp_kernels.Kernel" title="dynlearn.gp_kernels.Kernel"><code class="xref py py-class docutils literal notranslate"><span class="pre">Kernel</span></code></a> class implements a basic GP methods for numpy inputs, and
parallel versions for <a class="reference external" href="https://www.tensorflow.org/">Tensorflow</a>. This is
a very basic GP version not providing any optimisation of hyperparameters.</p>
<p class="rubric">Example</p>
<p>Optimise a latent test variable to fit target distribution:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># 2d input, 5 sample points</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">9.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">]])</span>
<span class="c1"># corresponding 2-multi output:</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.1</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.3</span><span class="p">,</span> <span class="mf">4.4</span><span class="p">],</span> <span class="p">[</span><span class="mf">5.5</span><span class="p">,</span> <span class="mf">6.6</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">7.7</span><span class="p">,</span> <span class="mf">8.8</span><span class="p">],</span> <span class="p">[</span><span class="mf">9.9</span><span class="p">,</span> <span class="mf">10.1</span><span class="p">]])</span>

<span class="n">k</span> <span class="o">=</span> <span class="n">Kernel</span><span class="p">(</span><span class="n">lengthscales</span><span class="o">=</span><span class="mf">1.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
           <span class="n">variance</span><span class="o">=</span><span class="mf">1.2</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span>
           <span class="n">likelihood_variance</span><span class="o">=</span><span class="mf">0.001</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span>
           <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
<span class="n">k</span><span class="o">.</span><span class="n">set_y</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># set up latent test input for prediction:</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">([[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.5</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float64&quot;</span><span class="p">)</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

<span class="n">m_target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.1</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.3</span><span class="p">,</span> <span class="mf">4.4</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float64&quot;</span><span class="p">)</span>
<span class="n">m_tf</span><span class="p">,</span> <span class="n">v_tf</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">tf_predict</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">m_tf</span><span class="p">)</span> <span class="c1"># mean prediction over z far from m_target</span>

<span class="c1"># loss(z) is log prob(m_target | z, k):</span>
<span class="n">mvn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">MultivariateNormalFullCovariance</span><span class="p">(</span><span class="n">m_tf</span><span class="p">,</span> <span class="n">v_tf</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">mvn</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">m_target</span><span class="p">))</span>

<span class="c1"># optimise latent z</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">opt</span><span class="o">.</span><span class="n">ScipyOptimizerInterface</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">sess</span><span class="p">)</span>

<span class="c1"># latent test input should be close to true x input:</span>
<span class="n">z_eval</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z_eval</span> <span class="o">-</span> <span class="n">k</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]))</span> <span class="o">&lt;</span>  <span class="mf">0.01</span>
</pre></div>
</div>
<dl class="class">
<dt id="dynlearn.gp_kernels.Kernel">
<em class="property">class </em><code class="descclassname">dynlearn.gp_kernels.</code><code class="descname">Kernel</code><span class="sig-paren">(</span><em>lengthscales</em>, <em>variance</em>, <em>likelihood_variance</em>, <em>x=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dynlearn/gp_kernels.html#Kernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.gp_kernels.Kernel" title="Permalink to this definition">¶</a></dt>
<dd><p>GP methods for squared exponential kernel. After definition using
lengthscales</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>lengthscales</strong> – lengthscales of input</li>
<li><strong>variance</strong> – amount of variation</li>
<li><strong>likelihood_variance</strong> – error variance</li>
<li><strong>x</strong> – input</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="dynlearn.gp_kernels.Kernel.add_x">
<code class="descname">add_x</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dynlearn/gp_kernels.html#Kernel.add_x"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.gp_kernels.Kernel.add_x" title="Permalink to this definition">¶</a></dt>
<dd><p>Add new samples to the current input values</p>
</dd></dl>

<dl class="method">
<dt id="dynlearn.gp_kernels.Kernel.add_y">
<code class="descname">add_y</code><span class="sig-paren">(</span><em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dynlearn/gp_kernels.html#Kernel.add_y"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.gp_kernels.Kernel.add_y" title="Permalink to this definition">¶</a></dt>
<dd><p>Add new samples to the current output values</p>
</dd></dl>

<dl class="method">
<dt id="dynlearn.gp_kernels.Kernel.np_predict">
<code class="descname">np_predict</code><span class="sig-paren">(</span><em>z</em>, <em>is_epsilon=False</em>, <em>is_cov=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dynlearn/gp_kernels.html#Kernel.np_predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.gp_kernels.Kernel.np_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict output for new inputs</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>z</strong> (<em>(</em><em>m</em><em>,</em><em>d</em><em>) </em><em>np.array</em>) – <em>m</em> input points of dim <em>d</em> (same as <strong>x</strong>)</li>
<li><strong>is_epsilon</strong> (<em>boolean</em>) – add measurement error</li>
<li><strong>is_cov</strong> (<em>boolean</em>) – return covariance matrix</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><p>tuple containing</p>
<blockquote>
<div><ul class="simple">
<li><dl class="first docutils">
<dt><strong>mean</strong> (<em>(m,k) np.array</em>): <em>m</em> mean predictions over <strong>z</strong> for</dt>
<dd><em>k</em> outputs</dd>
</dl>
</li>
<li><strong>var</strong> (<em>(m,m) np.array</em>): covariance of <strong>z</strong> inputs</li>
</ul>
</div></blockquote>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dynlearn.gp_kernels.Kernel.set_x">
<code class="descname">set_x</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dynlearn/gp_kernels.html#Kernel.set_x"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.gp_kernels.Kernel.set_x" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the input values for GP</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>(</em><em>n</em><em>,</em><em>d</em><em>) </em><em>np.array</em>) – n inputs of dim d</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dynlearn.gp_kernels.Kernel.set_y">
<code class="descname">set_y</code><span class="sig-paren">(</span><em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dynlearn/gp_kernels.html#Kernel.set_y"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.gp_kernels.Kernel.set_y" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the output (target) values</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>y</strong> (<em>(</em><em>n</em><em>,</em><em>k</em><em>) </em><em>np.array</em>) – k independent multioutputs for n inputs</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dynlearn.gp_kernels.Kernel.tf_predict">
<code class="descname">tf_predict</code><span class="sig-paren">(</span><em>z</em>, <em>is_epsilon=False</em>, <em>is_cov=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dynlearn/gp_kernels.html#Kernel.tf_predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.gp_kernels.Kernel.tf_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict output for new inputs, TensorFlow version</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>z</strong> (<em>(</em><em>m</em><em>,</em><em>d</em><em>) </em><em>tf.Variable</em>) – <em>m</em> input points of dim <em>d</em> (same as <strong>x</strong>)</li>
<li><strong>is_epsilon</strong> (<em>boolean</em>) – add measurement error</li>
<li><strong>is_cov</strong> (<em>boolean</em>) – return covariance matrix</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><p>tuple containing</p>
<blockquote>
<div><ul class="simple">
<li><dl class="first docutils">
<dt><strong>mean</strong> (<em>(m,k) tf.Tensor</em>): <em>m</em> mean predictions over <strong>z</strong> for</dt>
<dd><em>k</em> outputs</dd>
</dl>
</li>
<li><strong>var</strong> (<em>(m,m) tf.Tensor</em>): covariance of <strong>z</strong> inputs</li>
</ul>
</div></blockquote>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dynlearn.gp_kernels.Kernel.tf_recursive">
<code class="descname">tf_recursive</code><span class="sig-paren">(</span><em>u_col_tf</em>, <em>x0</em>, <em>is_epsilon=False</em>, <em>is_random=False</em>, <em>is_nonnegative=False</em>, <em>is_diff=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dynlearn/gp_kernels.html#Kernel.tf_recursive"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.gp_kernels.Kernel.tf_recursive" title="Permalink to this definition">¶</a></dt>
<dd><p>Iteratively solve the dynamical system defined by the GP providing
a (random) transition function as defined by the current GP inputs
and outputs and <code class="docutils literal notranslate"><span class="pre">u_col_tf</span></code> as external forcing. Start with <code class="docutils literal notranslate"><span class="pre">x0</span></code>
combined with <code class="docutils literal notranslate"><span class="pre">u_col_tf[0,:]</span></code> and along the iteration consider
input from <code class="docutils literal notranslate"><span class="pre">u_col_tf[1:,:]</span></code>. Returned are the values of the species
variables at each simulation step together with the forcing input.</p>
<p>TODO: in order to mimick the effect of drawing a single function from
the GP for the whole recursion one would have to constantly add
previous sampled outputs as new inputs to the GP. This is not done at
the moment for efficiency sake, so effectively each iteration draws a
new transition function from the GP. Future versions should include
this option.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>u_col_tf</strong> (<em>(</em><em>t</em><em>,</em><em>d</em><em>) </em><em>tf.Tensor</em>) – <em>d</em>-dim external forcing for <em>t</em> steps</li>
<li><strong>x0</strong> (<em>(</em><em>k</em><em>,</em><em>1</em><em>) </em><em>np.array</em>) – <em>k</em> initial values of species</li>
<li><strong>is_epsilon</strong> – assume measurement error</li>
<li><strong>is_random</strong> – use GP covariance uncertainty</li>
<li><strong>is_nonnegative</strong> – impose nonnegativity constraint on species</li>
<li><strong>is_diff</strong> – assume the species difference is modeled by GP</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><em>(t,d+k) tf.Tensor</em> of forcing input and simulated species,
first <em>d</em> columns return the <em>u</em> forcing input</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-dynlearn.learn">
<span id="gaussian-process-state-space-model"></span><h1>Gaussian process state space model<a class="headerlink" href="#module-dynlearn.learn" title="Permalink to this headline">¶</a></h1>
<p>Core module of package optimising the forcing input to the dynamical
system to achieve a target level of species</p>
<p>See <a class="reference internal" href="#module-dynlearn.demo" title="dynlearn.demo"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dynlearn.demo</span></code></a> for an example how to use this module</p>
<dl class="class">
<dt id="dynlearn.learn.FixedGaussGP">
<em class="property">class </em><code class="descclassname">dynlearn.learn.</code><code class="descname">FixedGaussGP</code><span class="sig-paren">(</span><em>lengthscales</em>, <em>variance</em>, <em>likelihood_variance</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dynlearn/learn.html#FixedGaussGP"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.learn.FixedGaussGP" title="Permalink to this definition">¶</a></dt>
<dd><p>A simple GP class with the usual squared exponential kernel
parameters</p>
<dl class="method">
<dt id="dynlearn.learn.FixedGaussGP.kernel_for_u">
<code class="descname">kernel_for_u</code><span class="sig-paren">(</span><em>u_tracks</em>, <em>sim</em>, <em>k=None</em>, <em>is_diff=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dynlearn/learn.html#FixedGaussGP.kernel_for_u"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.learn.FixedGaussGP.kernel_for_u" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs the simulation <em>sim</em> for the forcing inputs <em>u_tracks</em> and
adds the resulting input-output relationship to the GP <em>k</em>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>u_tracks</strong> (<em>(</em><em>t</em><em>,</em><em>k</em><em>) </em><em>np.array</em>) – the new forcing inputs</li>
<li><strong>sim</strong> (<a class="reference internal" href="#dynlearn.simulation.Simulation" title="dynlearn.simulation.Simulation"><em>simulation.Simulation</em></a>) – the experiment simulator</li>
<li><strong>k</strong> (<a class="reference internal" href="#dynlearn.gp_kernels.Kernel" title="dynlearn.gp_kernels.Kernel"><em>gp_kernels.Kernel</em></a>) – represents the GP, if None newly created</li>
<li><strong>is_diff</strong> – differences are modelled</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><p>A tuple with (<em>t</em> is number steps, <em>d</em> state dim including
forcing input, <em>m</em> is species dim only)</p>
<blockquote>
<div><ul class="simple">
<li><strong>k</strong> (<em>gp_kernels.Kernel</em>): the created or updated GP</li>
<li><strong>X_span</strong> (<em>(t-1,d) np.array</em>): new GP inputs</li>
<li><strong>Y_span</strong> (<em>(t-1,m) np.array</em>): new GP output</li>
</ul>
</div></blockquote>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="dynlearn.learn.Loss">
<em class="property">class </em><code class="descclassname">dynlearn.learn.</code><code class="descname">Loss</code><a class="reference internal" href="_modules/dynlearn/learn.html#Loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.learn.Loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Generic loss class</p>
</dd></dl>

<dl class="class">
<dt id="dynlearn.learn.RegularisedEndLoss">
<em class="property">class </em><code class="descclassname">dynlearn.learn.</code><code class="descname">RegularisedEndLoss</code><span class="sig-paren">(</span><em>target</em>, <em>target_ind</em>, <em>u_dim</em>, <em>time_ind</em>, <em>reg_weights=0.5</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dynlearn/learn.html#RegularisedEndLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.learn.RegularisedEndLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a loss function suitable for optimising the forcing input,</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>target</strong> (<em>float</em>) – value or 9999.0 for maximising, -9999.0 for minimising</li>
<li><strong>target_ind</strong> (<em>int</em>) – variable index of target variable (without u)</li>
<li><strong>u_dim</strong> (<em>int</em>) – dimension of forcing input part of tracks vector</li>
<li><strong>time_ind</strong> – step index at which to compute loss</li>
<li><strong>reg_weights</strong> – L1 regularisation terms</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="dynlearn.learn.make_u_col_tf">
<code class="descclassname">dynlearn.learn.</code><code class="descname">make_u_col_tf</code><span class="sig-paren">(</span><em>u_col</em>, <em>trainable_inds</em>, <em>u_type</em>, <em>u_max_limit=None</em>, <em>u_min_limit=0.0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dynlearn/learn.html#make_u_col_tf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.learn.make_u_col_tf" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the TF version of forcing input <em>u</em> with trainable structure
according to either a ‘peak’ or ‘step’ version of the input</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>u_col</strong> (<em>(</em><em>t</em><em>,</em><em>d</em><em>) </em><em>np.array</em>) – forcing <em>d</em>-dim inputs to dynamical system</li>
<li><strong>trainable_inds</strong> (<em>list</em><em>(</em><em>int</em><em>)</em>) – simulation steps where input can be optimised</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><em>(t,d)</em> tf.Tensor containing the trainable TF variables
corresponding to input</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="dynlearn.learn.search_u">
<code class="descclassname">dynlearn.learn.</code><code class="descname">search_u</code><span class="sig-paren">(</span><em>sim</em>, <em>loss</em>, <em>gp</em>, <em>knots</em>, <em>knot_values</em>, <em>x0</em>, <em>u_max_limit=None</em>, <em>n_epochs=6</em>, <em>n_samples=10</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dynlearn/learn.html#search_u"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dynlearn.learn.search_u" title="Permalink to this definition">¶</a></dt>
<dd><p>Main forcing input optimisation function using a GP to approximate
a dynamical system given by a simulator. In <code class="docutils literal notranslate"><span class="pre">n_epochs</span></code> rounds of
suggesting a forcing input followed by an experiment and improvement of
the GP the system is explored. In order to capture the GP uncertainty,
<code class="docutils literal notranslate"><span class="pre">n_samples</span></code> realisations of the recursive GP simulation are created.
The loss function can make use of these alternative pathways, eg by
only considering the mean or taking the variance into account.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>sim</strong> (<a class="reference internal" href="#dynlearn.simulation.Simulation" title="dynlearn.simulation.Simulation"><em>simulation.Simulation</em></a>) – the simulator for experiments</li>
<li><strong>loss</strong> (<a class="reference internal" href="#dynlearn.learn.Loss" title="dynlearn.learn.Loss"><em>Loss</em></a>) – target loss</li>
<li><strong>gp</strong> (<a class="reference internal" href="#dynlearn.learn.FixedGaussGP" title="dynlearn.learn.FixedGaussGP"><em>FixedGaussGP</em></a>) – GP for estimating dynamical system</li>
<li><strong>knots</strong> (<em>list</em><em>(</em><em>int</em><em>)</em>) – simulation steps where input can be optimised</li>
<li><strong>knot_values</strong> (<em>list</em><em>(</em><em>float</em><em>)</em>) – starting values for forcing input</li>
<li><strong>x0</strong> (<em>list</em><em>(</em><em>float</em><em>)</em>) – starting values for nonforced species</li>
<li><strong>u_max_limit</strong> (<em>float</em>) – limit on maximum for forcing input</li>
<li><strong>n_epochs</strong> (<em>int</em>) – number of experiments which can be performed</li>
<li><strong>n_samples</strong> (<em>int</em>) – number of random realisations from the GP recursion</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><p>A list item for each epoch. The item contains</p>
<blockquote>
<div><ul class="simple">
<li>the output of <cite>FixedGaussGP.kernel_for_u</cite> for the experiment</li>
<li><strong>u_col</strong> (<em>np.array</em>): the forcing inputs for the experiment</li>
</ul>
</div></blockquote>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="indices-and-tables">
<h1>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></li>
<li><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></li>
<li><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></li>
</ul>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="#">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Lorenz Wernisch.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.7.4</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="_sources/index.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>